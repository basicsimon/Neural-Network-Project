# -*- coding: utf-8 -*-
"""WNN_AnswersExercise03.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bSiEWfrKPtn2lgJtRkQxgqmsBDbbG_7b

Working with Neural Network Models

&copy; Hans Nieminen, Satakunta University of Applied Sciences

# Exercise 3.1
"""

neurons = 10**11
synapses_per_neuron = 10**3
bits_per_synapse = 4

bits = neurons * synapses_per_neuron * bits_per_synapse

Bytes = bits/8

kiloBytes = Bytes/1024
kiloBytes

megaBytes = kiloBytes/1024
megaBytes

gigaBytes = megaBytes/1024
gigaBytes

teraBytes = gigaBytes/1024
teraBytes

"""# Exercise 3.2"""

import numpy as np

def perceptron(x, w, b):
    v = np.dot(w, x) + b
    if v > 0:
      return 1
    else:
      return 0

inputs = np.array([[0.1, 0.2, 0.3],
                   [-0.3, 0.3, -0.2],
                   [0.1, 0.0, 0.2],
                   [0.4, 0.3, -0.4],
                   [0.2, 0.2, -0.1]])

weights = np.array([[0.5, -0.1, 0.3],
                    [0.1, 0.1, -0.2],
                    [-0.1, 0.3, -0.2],
                    [-0.2, 0.3, 0.2],
                    [0.1, -0.1, -0.1]])

biases = np.array([[-0.2],
                   [-0.4],
                   [0.3],
                   [0.1],
                   [-0.05]])

s = 0
for i in range(len(inputs)):
  s += perceptron(inputs[i], weights[i], biases[i])
print(s)

"""# Exercise 3.3"""

import numpy as np
from math import pi

def GELU(x):
  return 0.5*x*(1+np.tanh(np.sqrt(2/pi)*(x+0.044715*x**3)))

inputs = np.array([0.2, -0.1, 1.2, 0.7, -0.3, 0.1, -0.2])

outputs = GELU(inputs)

outputs

print(outputs.mean().round(3))

"""GELU is implemented also is PyTorch."""

import torch
from torch.nn.functional import gelu

inputs2 = torch.tensor([0.2, -0.1, 1.2, 0.7, -0.3, 0.1, -0.2])
outputs2 = gelu(inputs2)
outputs2

"""Visualization of GELU vs. ReLU."""

import matplotlib.pyplot as plt

x = np.linspace(start=-4,stop=3, num=50)
x

def ReLU(value):
    return (value > 0) * value

plt.plot(x, GELU(x), label='GELU')
plt.plot(x, ReLU(x), label='ReLU')
plt.legend()

"""# Exercise 3.4

Number of parameters is the number of connections, i.e. #$V_1$ + #$V_2$ + #$V_3 = 16 + 10 + 3 = 29$.
"""
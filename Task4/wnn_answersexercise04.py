# -*- coding: utf-8 -*-
"""WNN_AnswersExercise04.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lmbYCFL9prtQS-TqMnVPrrfvP_q3IzO2

Working with Neural Network Models

Â© Hans Nieminen, Satakunta University of Applied Sciences

# Exercise 4.3

input - 1st hidden layer: $(30 + 1)\times 20 = 620$

1st hidden - 2nd hidden layer: $(20+1)\times 9=189$

2nd hidden - 3rd hidden layer: $(9+1)\times 4=40$

3rd hidden - output layer: $(4+1)\times 2=10$

Total number of parameters: $620+189+40+10=859$
"""

input_layer = 30
hidden1 = 20
hidden2 = 9
hidden3 = 4
output_layer = 2
biases = True
parameter_counts = {
 'hidden1':(input_layer+biases)*hidden1,
 'hidden2':(hidden1+biases)*hidden2,
 'hidden3':(hidden2+biases)*hidden3,
 'output':(hidden3+biases)*output_layer
}
parameter_counts

print('Total number of parameters is', sum(parameter_counts.values()))

"""# Exercise 4.4"""

import numpy as np

def softmax(x):
    dim = x.ndim
    x = np.atleast_2d(x)
    result = np.empty(x.shape)
    for i in range(x.shape[0]):
        result[i,:] = np.exp(x[i]) / np.sum(np.exp(x[i]), axis=0)
    # if parameter x was originally 1D, return a vector
    if dim == 1:
      result = result[0]
    return result

a = np.array([0.56, 2.3, 6.2, 2.7, 7.4, 3.2, 0.82, 3.7])

outputs = softmax(a)
outputs.round(3)

ind = np.where(outputs.round(3) == 0.011)[0][0]
print(a[ind])